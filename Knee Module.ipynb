{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ead799",
   "metadata": {},
   "source": [
    "#### Immport modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309dda71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca5b33",
   "metadata": {},
   "source": [
    "#### Read images creating a dataframe  and class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bebeea64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df lenght:  5778   test_df length:  1656   valid_df length:  826\n",
      "The number of classes in the dataset is:  5\n",
      "            CLASS               IMAGE COUNT \n",
      "           Doubtful                1046     \n",
      "           Healthy                 2286     \n",
      "           Minimal                 1516     \n",
      "           Moderate                 757     \n",
      "            Severe                  173     \n",
      "Healthy  has the most images=  2286   Severe  has the least images=  173\n",
      "average height=  224  average width=  224 aspect ratio=  1.0\n"
     ]
    }
   ],
   "source": [
    "train_path=r'C:\\Users\\gihan\\Desktop\\ResearchProject\\Dataset\\train'\n",
    "test_path=r'C:\\Users\\gihan\\Desktop\\ResearchProject\\Dataset\\test'\n",
    "valid_path=r'C:\\Users\\gihan\\Desktop\\ResearchProject\\Dataset\\val'\n",
    "list_of_classes=['Healthy', 'Doubtful', 'Minimal', 'Moderate', 'Severe']\n",
    "for d in [train_path, test_path, valid_path]:\n",
    "    filepaths = []\n",
    "    labels=[] \n",
    "    classlist=os.listdir(d)   \n",
    "    for klass in classlist:\n",
    "        intklass=int(klass)\n",
    "        label=list_of_classes[intklass]\n",
    "        classpath=os.path.join(d, klass)\n",
    "        flist=os.listdir(classpath)        \n",
    "        for f in flist:\n",
    "            fpath=os.path.join(classpath,f)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(label)\n",
    "    Fseries=pd.Series(filepaths, name='filepaths')\n",
    "    Lseries=pd.Series(labels, name='labels')        \n",
    "    pdf=pd.concat([Fseries, Lseries], axis=1)\n",
    "    if d == test_path:\n",
    "        test_df=pdf\n",
    "    elif d == valid_path:\n",
    "        valid_df=pdf\n",
    "    else:\n",
    "        train_df=pdf\n",
    "print('train_df lenght: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))\n",
    "\n",
    "# get the number of classes and the images count for each class in train_df\n",
    "classes=sorted(list(train_df['labels'].unique()))\n",
    "class_count = len(classes)\n",
    "print('The number of classes in the dataset is: ', class_count)\n",
    "groups=train_df.groupby('labels')\n",
    "print('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))\n",
    "countlist=[]\n",
    "classlist=[]\n",
    "for label in sorted(list(train_df['labels'].unique())):\n",
    "    group=groups.get_group(label)\n",
    "    countlist.append(len(group))\n",
    "    classlist.append(label)\n",
    "    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))\n",
    "\n",
    "# get the classes with the minimum and maximum number of train images\n",
    "max_value=np.max(countlist)\n",
    "max_index=countlist.index(max_value)\n",
    "max_class=classlist[max_index]\n",
    "min_value=np.min(countlist)\n",
    "min_index=countlist.index(min_value)\n",
    "min_class=classlist[min_index]\n",
    "print(max_class, ' has the most images= ',max_value, ' ', min_class, ' has the least images= ', min_value)\n",
    "\n",
    "# lets get the average height and width of a sample of the train images\n",
    "ht=0\n",
    "wt=0\n",
    "\n",
    "# select 100 random samples of train_df\n",
    "train_df_sample=train_df.sample(n=100, random_state=123,axis=0)\n",
    "for i in range (len(train_df_sample)):\n",
    "    fpath=train_df_sample['filepaths'].iloc[i]\n",
    "    img=plt.imread(fpath)\n",
    "    shape=img.shape\n",
    "    ht += shape[0]\n",
    "    wt += shape[1]\n",
    "print('average height= ', ht//100, ' average width= ', wt//100, 'aspect ratio= ', ht/wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c32982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy 2286\n",
      "Moderate 757\n",
      "Severe 173\n"
     ]
    }
   ],
   "source": [
    "drop_classes = ['Minimal', 'Doubtful']\n",
    "\n",
    "train_df = train_df[~train_df['labels'].isin(drop_classes)]\n",
    "valid_df = valid_df[~valid_df['labels'].isin(drop_classes)]  \n",
    "test_df = test_df[~test_df['labels'].isin(drop_classes)]\n",
    "\n",
    "# Update the list of classes \n",
    "list_of_classes = [c for c in list_of_classes if c not in drop_classes]\n",
    "\n",
    "# Re-calculate the total classes\n",
    "class_count = len(list_of_classes)\n",
    "\n",
    "# Re-count the images per class\n",
    "groups = train_df.groupby('labels')  \n",
    "for label in list_of_classes:\n",
    "    group = groups.get_group(label) \n",
    "    print(label, len(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8e51d",
   "metadata": {},
   "source": [
    "#### Triming train_df  no class has more than 500 image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1388813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after trimming, the maximum samples in any class is now  500  and the minimum samples in any class is  173\n"
     ]
    }
   ],
   "source": [
    "def trim(df, max_samples, min_samples, column):\n",
    "    df=df.copy()\n",
    "    groups=df.groupby(column)    \n",
    "    trimmed_df = pd.DataFrame(columns = df.columns)\n",
    "    groups=df.groupby(column)\n",
    "    for label in df[column].unique(): \n",
    "        group=groups.get_group(label)\n",
    "        count=len(group)    \n",
    "        if count > max_samples:\n",
    "            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n",
    "            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "        else:\n",
    "            if count>=min_samples:\n",
    "                sampled_group=group        \n",
    "                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)\n",
    "    return trimmed_df\n",
    "\n",
    "max_samples=500 # since each class has more than 200 images all classes will be trimmed to have 200 images per class\n",
    "min_samples=173\n",
    "column='labels'\n",
    "train_df= trim(train_df, max_samples, min_samples, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b12e98",
   "metadata": {},
   "source": [
    "#### Balancing train_df so each class has 500 images using augmentation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
